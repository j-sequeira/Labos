{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gs7FgJ_WRLx"
   },
   "source": [
    "# **3. Ajustes y regresiones**\n",
    "\n",
    "En esta guía vas a encontrar herramientas básicas para efectuar *estimaciones de parámetros* de tus modelos. Esto se hará mediante el ajuste (regresión) lineal o no lineal de tus parámetros que minimize las diferencias entre las predicciones de tu modelo y tus observaciones.\n",
    "\n",
    "Junto con las bibliotecas usuales se agrega la funcionalidad `curve_fit` de `scipy.optimize` que permitirá sistematizar los ajustes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "His45GRb3zEl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkPaQH4L-ggU"
   },
   "source": [
    "## 3.1. Modelo y observaciones\n",
    "\n",
    "A la hora de efectuar un análisis por regresión (ajuste) tenés que poner en claro qué objetivo te lleva a realizarlo.\n",
    "\n",
    "Suponé que tenés un conjunto de $n$ pares de valores experimentales $(X_n,Y_n)$ tales que, por ejemplo, $X:=L$ represente la longitud e $Y:=T$ el periodo de un péndulo. También suponé que existe cierta relación funcional $Y(X)$, que puede ser conocida o no.\n",
    "\n",
    "Si la relación funcional no es conocida, un objetivo posible es intentar estudiar qué *modelo* $Y(X)$ permite explicar la relación entre los resultados $Y_n(X_n)$ obtenidos. Esto se realiza, por ejemplo, proponiendo un modelo o varios que permitan explicar tus resultados.\n",
    "\n",
    "Ahora pensá que el modelo ya fue propuesto y es conocido, aunque también depende de uno o varios *parámetros* desconocidos. Por ejemplo, suponé que tu modelo depende según cierta relación $Y(X;\\alpha)$; donde tu parámetro $\\alpha:=g$ puede ser la aceleración de la gravedad (supongamos constante). Tu objetivo ahora es *estimar* el valor de $\\alpha$ de tu modelo que mejor explique tus resultados experimentales.\n",
    "\n",
    "Con este último objetivo en mente, la propuesta es que puedas realizar la estimación del parámetro de un modelo conocido mediante ajustes. Suponé entonces que vas a estimar la aceleración de la gravedad $g$, a partir de un modelo conocido que relaciona el periodo $T$ de un péndulo con su longitud $L$, y que dicho modelo puede aproximarse como\n",
    "\n",
    "$$ T(L;g)=2\\pi \\sqrt{\\frac{L}{g}} \\; . $$\n",
    "\n",
    "Para empezar, tendrías que cargar tus datos experimentales $(L_n,T_n)$, junto con sus correspondientes incertezas $(\\Delta L_n, \\Delta T_n)$. Una forma de hacerlo es cargando tus datos en `arrays` con nombres `L`, `dL`, `T` y `dT` como se ejemplifica en el siguiente bloque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17pyHOsr4RK9"
   },
   "outputs": [],
   "source": [
    "L = np.array([\n",
    "  2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6,\n",
    "  2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3,\n",
    "  3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0\n",
    "  ])\n",
    "\n",
    "dL = np.array([\n",
    "  0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
    "  0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
    "  0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1\n",
    "  ])\n",
    "\n",
    "T = np.array([\n",
    "  2.82, 2.90, 2.91, 3.10, 3.12, 3.22, 3.25,\n",
    "  3.29, 3.32, 3.47, 3.53, 3.54, 3.64, 3.71,\n",
    "  3.61, 3.73, 3.83, 3.87, 3.85, 3.91, 4.07\n",
    "  ])\n",
    "\n",
    "dT = np.array([\n",
    "  0.01, 0.01, 0.06, 0.06, 0.01, 0.05, 0.01,\n",
    "  0.01, 0.04, 0.05, 0.06, 0.01, 0.05, 0.06,\n",
    "  0.09, 0.02, 0.02, 0.01, 0.06, 0.05, 0.05\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KY3bAfosaeu4"
   },
   "source": [
    "## 3.2. Regresión lineal\n",
    "\n",
    "La forma más sencilla en la que podés encarar tu objetivo es mediante un *ajuste o regresión lineal*.\n",
    "\n",
    "Notemos que la ecuación aproximada del periodo del péndulo, tal como fue escrita, no es lineal. Para salvar esta situación fijate que podés reescribir la misma como\n",
    "\n",
    "$$ T(X ; \\alpha)= \\overbrace{\\frac{2\\pi}{\\sqrt{g}}}^{\\alpha} \\; \\underbrace{\\sqrt{L}}_{X} = \\alpha X \\; ,$$\n",
    "\n",
    "de modo que tu problema se reduce a estudiar la relación lineal entre $T$ y $X$ para poder estimar la pendiente $\\alpha$ y, por lo tanto, estimar $g$. Asimismo, corresponderá propagar la incerteza de $X$ como\n",
    "\n",
    "$$ \\Delta X = \\sqrt{ \\bigg( \\frac{\\partial{X}}{\\partial{L}} \\Delta L \\bigg)^2} = \\frac{\\Delta L}{2 \\sqrt{L}} .$$\n",
    "\n",
    "Queda como tarea aparte revisar que, aplicando $\\log()$ a ambos miembros de la ecuación original del periodo del péndulo, es posible también linealizar en forma alternativa la relación. La única diferencia es que, en ese caso, ambas variables $T$ y $L$ serán absorbidas por otras.\n",
    "\n",
    "Bajo estas consideraciones, podés computar las nuevas variables $X_n$ y $\\Delta X_n$ con el siguiente bloque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSu0-ool8cHe"
   },
   "outputs": [],
   "source": [
    "X = np.sqrt(L)\n",
    "dX = dL/2/np.sqrt(L)\n",
    "\n",
    "print('X  =',  X)\n",
    "print('dX =', dX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLfSnBxLsZ8u"
   },
   "source": [
    "Habiendo organizado el conjunto de mediciones experimentales según $(T_n,X_n)$ con sus respectivos errores, resta solo realizar la regresión lineal correspondiente a $T=\\alpha X$ para estimar el valor de $\\alpha$.\n",
    "\n",
    "Primero podés definir en tu código una función lineal `TX` que sólo tenga pendiente `a`; es decir, la ordenada al origen la consideramos, por hipótesis de nuestro modelo, vale cero.\n",
    "\n",
    "Luego, llamando a la función `curve_fit` de `scipy.optimize` que realizará el ajuste por *cuadrados mínimos*, vas a poder estimar el parámetro `a` ($\\alpha$) y su incerteza estadística `da` ($\\Delta \\alpha$).\n",
    "\n",
    "A continuación podés ejecutar esta regresión lineal y verificar los valores obtenidos para $\\alpha$ y $\\Delta \\alpha$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oxn8hG6BmMFv"
   },
   "outputs": [],
   "source": [
    "def TX(X, a):\n",
    "  return a*X\n",
    "\n",
    "popt, pcov = curve_fit(TX, X, T)\n",
    "\n",
    "a = popt[0]\n",
    "da = np.sqrt(pcov[0,0])\n",
    "\n",
    "print('a  =',  a)\n",
    "print('da =', da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft4C10rLuPUI"
   },
   "source": [
    "Haciendo uso de tu estimación de $\\alpha$ vas a poder representar gráficamente la curva $T(X;\\alpha)$ correspondiente a ese ajuste. De este modo, vas a poder contrastar este ajuste con los valores empíricos $T_n(X_n)$ y sus correspondientes incertezas.\n",
    "\n",
    "Siguiendo esta estrategia, en el bloque a continuación podés graficar $(X_n\\pm\\Delta X_n,T_n\\pm\\Delta T_n)$ en contraste con $T(X;\\alpha)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkcgyolVZMLS"
   },
   "outputs": [],
   "source": [
    "x_min = 1.3\n",
    "x_max = 2.1\n",
    "\n",
    "axis = np.linspace(x_min, x_max, 100)\n",
    "\n",
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "plt.errorbar(X, T, xerr=dX, yerr=dT,marker='o',  markersize=4, linestyle=\"None\", label=\"Mediciones\")\n",
    "plt.plot(axis, TX(axis, *popt), 'r-', label=\"Regresión lineal\")\n",
    "\n",
    "plt.axis([x_min, x_max, TX(x_min, *popt), TX(x_max, *popt)])\n",
    "plt.title('Estimación de $\\\\alpha$ por regresión lineal')\n",
    "plt.xlabel('Raíz cuadrada de la longitud del péndulo (m$^{1/2}$)')\n",
    "plt.ylabel('Periodo de oscilación (s)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_E5NHzhupCX"
   },
   "source": [
    "Por último, es fundamental que no olvides el objetivo primero que te impulsó realizar esta regresión: estimar el valor de $g$. Para ello, solo basta invertir la relación $g(\\alpha)$ y propagar su incerteza de modo tal que\n",
    "\n",
    "$$ g = \\frac{4\\pi^2}{\\alpha^2} \\;, \\;\\;\\; \\Delta g = \\frac{8 \\pi^2}{\\alpha^3} \\Delta \\alpha \\;,$$\n",
    "\n",
    "para que, finalmente, puedas resolver la estimación deseada de $g\\pm\\Delta g$ con el siguiente bloque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLXkmz97uqAm"
   },
   "outputs": [],
   "source": [
    "g = 4*np.pi**2/popt[0]**2\n",
    "dg = 8*np.pi**2*da/a**3\n",
    "\n",
    "print('g  =',  g)\n",
    "print('dg =', dg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fosSShERGmku"
   },
   "source": [
    "## 3.3. Regresión no lineal\n",
    "\n",
    "Siguiendo una estrategia análoga a la del ajuste lineal, es posible definir un ajuste o regresión *no lineal* que permita nuevamente estimar uno o varios parámetros para una dada relación.\n",
    "\n",
    "Para este caso, podés volver a la relación original $T(L;g)$ no linealizada, y estimar estimar directamente el parámetro $g$ sin necesidad reescribir nuevas variables ni parámetros.\n",
    "\n",
    "En los siguientes bloques vas a podés realizar el ajuste no lineal para la ecuación dada, estimar nuevamente el parámetro $g$ y realizar el correspondiente gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDoCNT3kw3NL"
   },
   "outputs": [],
   "source": [
    "def TL(L, g):\n",
    "  return 2*np.pi*np.sqrt(L/g)\n",
    "\n",
    "popt, pcov = curve_fit(TL, L, T)\n",
    "\n",
    "g = popt[0]\n",
    "dg = np.sqrt(pcov[0,0])\n",
    "\n",
    "print('g  =',  g)\n",
    "print('dg =', dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXTCQGqqyD1J"
   },
   "outputs": [],
   "source": [
    "x_min = 1.7\n",
    "x_max = 4.4\n",
    "\n",
    "axis = np.linspace(x_min, x_max, 100)\n",
    "\n",
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "plt.errorbar(L, T, xerr=dL, yerr=dT, marker='o', markersize=4, linestyle=\"None\", label=\"Mediciones\")\n",
    "plt.plot(axis, TL(axis, *popt), 'r-', label=\"Regresión no lineal\")\n",
    "\n",
    "plt.axis([x_min, x_max, TL(x_min, *popt), TL(x_max, *popt)])\n",
    "plt.title('Estimación de $g$ por regresión no lineal')\n",
    "plt.xlabel('Longitud del péndulo (m)')\n",
    "plt.ylabel('Periodo de oscilación (s)')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csURdDVYANQT"
   },
   "source": [
    "Algo que corresponde resaltar, válido tanto en el caso lineal como no lineal, es que en el ajuste de las regresiones anteriores no se tomaron en cuenta las incertezas especificadas en cada medición. En cambio, se consideró que cada medición contribuía con el mismo *peso estadístico* a la hora de realizar el ajuste.\n",
    "\n",
    "Otra opción posible, de la que restaría discutir en qué sentido puede ser (o no) más válida que la anterior elección, es indicarle al ajuste que considere las incertezas de cada medición. Para ello, en el bloque a continuación se repite el ajuste de siempre, con la diferencia de haber designado en `sigma` los errores de $T$ para que sean pesados en el ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMeS_v5lATmx"
   },
   "outputs": [],
   "source": [
    "def TL(L, g):\n",
    "  return 2*np.pi*np.sqrt(L/g)\n",
    "\n",
    "popt, pcov = curve_fit(TL, L, T, sigma = dT)\n",
    "\n",
    "g = popt[0]\n",
    "dg = np.sqrt(pcov[0,0])\n",
    "\n",
    "print('g  =',  g)\n",
    "print('dg =', dg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ4bq2jUYm0_"
   },
   "source": [
    "## 3.4. Análisis de regresión\n",
    "\n",
    "Una pregunta válida a la hora de analizar tu regresión es: ¿cuál es el poder predictivo de tu modelo?\n",
    "\n",
    "La respuesta a esta pregunta, en principio, no es sencilla. Una forma posible de acercarse a una respuesta es contrastando modelos distintos y, luego, identificar qué modelo permitirá predecir más correctamente un nuevo conjunto de observaciones.\n",
    "\n",
    "Otra pregunta, con una respuesta un poco más sencilla, es: ¿cuán bien tu modelo propuesto se ajusta a tus observaciones? Esto no responde estrictamente el poder predictivo de tu modelo, pero es un primer acercamiento necesario.\n",
    "\n",
    "Siguiendo la línea de esta última pregunta, y dado un conjunto de mediciones ya realizadas, podés intentar al menos verificar cuál es la *bondad del ajuste*: cuán bien tu modelo se ajusta a tus observaciones. Esto no explica que tu modelo sea el correcto, pero sí da cuenta cuán bien tus datos se ajustan al mismo.\n",
    "\n",
    "A modo de ejemplo, en esta guía derivamos un modelo para $T(L;g)$ dado por\n",
    "\n",
    "$$ T_1(L;g) = \\frac{2\\pi}{\\sqrt{g}} \\sqrt{L} \\; , $$\n",
    "\n",
    "en el régimen de pequeñas oscilaciones. Sin embargo, si no hubieramos podido derivar el modelo anterior (a priori correcto) podríamos haber propuesto un modelo totalmente distinto como\n",
    "\n",
    "$$ T_2(L;g) = \\frac{7\\pi}{2g} L \\; , $$\n",
    "\n",
    "tal que, por ejemplo, la relación entre el periodo y la longitud sea lineal con ordenada al origen nula.\n",
    "\n",
    "En el bloque a continuación podés hacer, para el mismo conjunto de datos, las regresiones de ambos modelos para estimar sus parámetros, junto con los gráficos de los mismos. Como se puede observar, si bien las estimaciones parecieran ser similares a las esperadas, no así las relaciones funcionales frente a los datos: el modelo dado por $T1$ pareciera ser más predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRGC1Z0kkrrv"
   },
   "outputs": [],
   "source": [
    "def T1(L, g):\n",
    "  return 2*np.pi*np.sqrt(L/g)\n",
    "\n",
    "def T2(L, g):\n",
    "  return 7*np.pi*L/2/g\n",
    "\n",
    "popt1, pcov1 = curve_fit(T1, L, T)\n",
    "popt2, pcov2 = curve_fit(T2, L, T)\n",
    "\n",
    "g1 = popt1[0]\n",
    "g2 = popt2[0]\n",
    "dg1 = np.sqrt(pcov1[0,0])\n",
    "dg2 = np.sqrt(pcov2[0,0])\n",
    "\n",
    "x_min = 1.7\n",
    "x_max = 4.4\n",
    "\n",
    "axis = np.linspace(x_min, x_max, 100)\n",
    "\n",
    "plt.figure(figsize=(8,6),dpi=100)\n",
    "plt.errorbar(L, T, xerr=dL, yerr=dT, marker='o', markersize=4, linestyle=\"None\", label=\"Mediciones\")\n",
    "plt.plot(axis, T1(axis, *popt1), 'r-', label=\"Regresión (modelo $T1$)\")\n",
    "plt.plot(axis, T2(axis, *popt2), 'g-', label=\"Regresión (modelo $T2$)\")\n",
    "\n",
    "plt.axis([x_min, x_max, T1(x_min, *popt), T1(x_max, *popt)])\n",
    "plt.title('Análisis de regresión entre modelos $T_1$ y $T_2$')\n",
    "plt.xlabel('Longitud del péndulo (m)')\n",
    "plt.ylabel('Periodo de oscilación (s)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('g1  =',  g1)\n",
    "print('dg1 =', dg1)\n",
    "print('g2  =',  g2)\n",
    "print('dg2 =', dg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRyy42c_yPPL"
   },
   "source": [
    "Una forma de evaluar la bondad de un ajuste es mediante la aplicación de un *test estadístico*. Hay distintos tipos de tests, los cuales varían en su uso, destino, calidad, limitaciones, entre otros factores.\n",
    "\n",
    "Una forma inteligente de construir un test estadístico es a partir de considerar cómo se construye la regresión usualmente: *ajuste por cuadrados mínimos*. Este procedimiento lo que busca es encontrar el mínimo valor posible de la *suma de los cuadrados de los residuos*\n",
    "\n",
    "$$ \\textrm{RSS} = \\sum_{i=1}^N (y_i-\\hat{y}_i)^2 \\;,$$\n",
    "\n",
    "donde $y_i$ son cada uno de los $N$ valores observados y $f(x_i):=\\hat{y_i}$ son los valores del modelo que estamos ajustando. Luego, este algoritmo o procedimiento, buscará los parámetros del modelo (en nuestro ejemplo $g$) tal que la RSS sea mínima.\n",
    "\n",
    "Un test muy difundido, que se favorece del propio procedimiento de ajuste, es el denominado *Test $\\chi^2$ (chi cuadrado) de Pearson* con estadístico\n",
    "\n",
    "$$ \\chi^2_\\textrm{Pearson} = \\sum_{i=1}^N \\frac{(y_i-\\hat{y}_i)^2}{\\hat{y}_i} \\;.$$\n",
    "\n",
    "Otro test, que sigue el mismo espíritu, es el *Test $\\chi^2_\\nu$ Reducido*, cuyo estadístico es\n",
    "\n",
    "$$ \\chi^2_\\nu = \\frac{1}{\\nu} \\sum_{i=1}^N \\frac{(y_i-\\hat{y})^2}{\\sigma_i^2} \\;, \\;\\;\\; \\nu=N-m \\;, $$\n",
    "\n",
    "donde $\\sigma_i$ son las incertezas correspondientes a cada $y_i$; y $\\nu$ el número de grados de libertad, calculado como la diferencia entre el número total de observaciones $(N)$ y el número total de parámetros que se ajustarón $(m)$.\n",
    "\n",
    "Por razones históricas, en muchas disciplinas se suele mencionar también el *coeficiente de determinación*\n",
    "\n",
    "$$ R^2 = 1 - \\frac{\\sum (y_i-\\hat{y}_i)^2}{\\sum (y_i-\\bar{y})^2} \\;,$$\n",
    "\n",
    "donde $\\bar{y}$ es el promedio de los valores observados. Cabe destacar que el mismo no explica la bondad de una regresión (ni siquiera en un caso lineal); en cambio, el $R^2$ explica la correlación entre variables observadas y teóricas (es decir, si son 1:1), y su utilidad real frente a otros estadísticos es ampliamente discutida (https://data.library.virginia.edu/is-r-squared-useless/).\n",
    "\n",
    "En el bloque a continuación incluimos tres estadísticos discutidos: el $\\chi^2$ (chi cuadrado) de Pearson; el $\\chi^2_\\nu$ reducido; y el coeficiente de determinación $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsyykwcqHRlZ"
   },
   "outputs": [],
   "source": [
    "def pearson_chi_sq(y, f):\n",
    "  # https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test\n",
    "  return np.sum((y-f)**2/f)\n",
    "\n",
    "def reduced_chi_sq(y, f, sd, m):\n",
    "  # https://en.wikipedia.org/wiki/Reduced_chi-squared_statistic\n",
    "  return np.sum(((y-f)/sd)**2) / (len(y)-m)\n",
    "\n",
    "def r_sq(y, f):\n",
    "  # https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "  rss = np.sum((y-f)**2)\n",
    "  tss = np.sum((y-np.mean(y))**2)\n",
    "  return 1 - rss/tss\n",
    "  # the following not always holds true\n",
    "  # ess = np.sum((f-np.mean(y))**2)\n",
    "  # return ess/tss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pT1HgdVi31t-"
   },
   "source": [
    "Para evaluar la bondad del ajuste recomendamos utilizar el $\\chi^2_\\nu$ reducido, ya que el mismo resulta más sencillo de interpretar. Para este test en particular, se pueden seguir las siguientes reglas: si $\\chi^2_\\nu\\gg1$, el modelo propuesto es pobre; si $\\chi^2_\\nu>1$, el modelo es compatible con las observaciones pero habría una subestimación de las incertezas; si $\\chi^2_\\nu<1$, el modelo es compatible pero habría una sobreestimación de las incertezas.\n",
    "\n",
    "Cuando hablamos de subestimar incertezas nos referimos, en cierto sentido, a que las barras de error se superponen con la curva teórica menos veces de lo esperado; contrariamente, sobreestimar las incertezas implica que las barras de error se superponen con la curva teórica más veces de lo esperado. Una simulación útil para entender estos conceptos se puede encontrar en https://phet.colorado.edu/en/simulation/curve-fitting\n",
    "\n",
    "Entonces, como regla general, lo que se busca idealmente es que $\\chi^2_\\nu=1$; es decir, que no haya ni subestimación ni sobreestimación de las incertezas. \n",
    "\n",
    "En el bloque a continuación se realiza el test $\\chi^2_\\nu$ reducido para los dos modelos propuestos $T_1$ y $T_2$, en cada uno haciendo uso de los valores de $g_1$ y $g_2$ obtenidos en cada respectiva regresión. Puede observase que el primer modelo $T_1$ tiene un $\\chi^2_\\nu\\approx 1$, por lo que el modelo es compatible con las observaciones (aunque presenta leve subestimación); mientras que el modelo $T_2$ tiene $\\chi^2_\\nu\\gg 1$, por lo que el modelo resulta pobre e incompatible con las observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dized-5Nktk7"
   },
   "outputs": [],
   "source": [
    "test_modelo_1 = reduced_chi_sq(T,T1(L,g1),dT,1)\n",
    "test_modelo_2 = reduced_chi_sq(T,T2(L,g2),dT,1)\n",
    "\n",
    "print('Test Chi-Sq reducido (modelo 1): ', test_modelo_1)\n",
    "print('Test Chi-Sq reducido (modelo 2): ', test_modelo_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dwyxbl3n-l2A"
   },
   "source": [
    "> *Documento elaborado por Adán Garros (adan@garros.net) bajo licencia [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.es). Se agradece especialmente a Verónica Pérez Schuster por la revisión del contenido. Resultan bienvenidos comentarios y sugerencias. Última actualización: 2021-10-01.*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "guia_colab_03_ajustes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
